{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flowers_Recognition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXgJ6uT1NydQ"
      },
      "source": [
        "Assignment: Flowers Recognition <br>\n",
        "Dataset Description:<br>\n",
        "\n",
        "This dataset contains 4242 images of flowers.<br>\n",
        "The data collection is based on the data flicr, google images, yandex images.<br>\n",
        "You can use this datastet to recognize plants from the photo.<br>\n",
        "\n",
        "Attribute Information:<br>\n",
        "The pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion.<br>\n",
        "For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. <br>\n",
        "<b>Also explore how to resize images in tensorflow and then resize all the images to a same size. </b> <br>\n",
        "This is a Multiclass Classification Problem.<br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVj_005imtk7",
        "outputId": "ab0f6cf5-aa82-459f-e142-aa8bdb358684"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7vy-ktuOKJH"
      },
      "source": [
        "WORKFLOW : <br>\n",
        "Load Data <br>\n",
        "Split into 60 and 40 ratio.<br>\n",
        "Encode labels.<br>\n",
        "Create Model<br>\n",
        "Compilation Step (Note : Its a Multiclass Classification problem , select loss , metrics according to it)<br>\n",
        "Train the Model.<br>\n",
        "If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .<br>\n",
        "Prediction should be > 85%<br>\n",
        "Evaluation Step<br>\n",
        "Prediction<br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri3Bg5qfPRic"
      },
      "source": [
        "Data : <br>\n",
        "https://drive.google.com/file/d/1-OX6wn5gA-bJpjPNfSyaYQLz-A-AB_uj/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTtg3WuGTA1o"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIvOjeyhhiGW"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "from pathlib import Path\n",
        "import glob"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWm_1IiThiGX"
      },
      "source": [
        "img_dir0='/content/drive/MyDrive/flowers/daisy'\n",
        "img_dir1='/content/drive/MyDrive/flowers/dandelion'\n",
        "img_dir2='/content/drive/MyDrive/flowers/rose'\n",
        "img_dir3='/content/drive/MyDrive/flowers/sunflower'\n",
        "img_dir4='/content/drive/MyDrive/flowers/tulip'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mL7GQDFpu1ed",
        "outputId": "a10ab69c-1c9c-4f6b-de9a-a97674b3cf69"
      },
      "source": [
        "img_dir3"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/flowers/sunflower'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua5zXyBGhiGZ"
      },
      "source": [
        "def read_imgs(img_dir_path):\n",
        "  for img in glob.glob(img_dir_path+\"/*.jpg\"):\n",
        "    img=cv2.imread(img)\n",
        "    output=cv2.resize(img/255,(150,150))\n",
        "    yield output"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESXrWUpOonuX"
      },
      "source": [
        "output0=np.array(list(read_imgs(img_dir0)))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNGi3xFit8WS"
      },
      "source": [
        "output1=np.array(list(read_imgs(img_dir1)))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMcg6Mhkt8wj"
      },
      "source": [
        "output2=np.array(list(read_imgs(img_dir2)))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNDUexKZt82P"
      },
      "source": [
        "output3=np.array(list(read_imgs(img_dir3)))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL-ZVGFMt89r"
      },
      "source": [
        "output4=np.array(list(read_imgs(img_dir4)))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsKMgq7tqL3d"
      },
      "source": [
        "# giving labels to images\n",
        "label0=np.zeros((output0.shape[0],1))\n",
        "label1=np.ones((output1.shape[0],1))\n",
        "label2=np.ones((output2.shape[0],1))*2\n",
        "label3=np.ones((output3.shape[0],1))*3\n",
        "label4=np.ones((output4.shape[0],1))*4"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08TcKJ9TssBc",
        "outputId": "8e669a5e-f187-4143-efa4-f1fd642df7b3"
      },
      "source": [
        "data=np.concatenate((output0,output1,output2,output3,output4))\n",
        "data= data.reshape(data.shape[0], data.shape[1]*data.shape[2]*data.shape[3])\n",
        "data.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4323, 67500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_tYasB8tCdS",
        "outputId": "009df272-b75b-472b-815d-6a68521f8ecf"
      },
      "source": [
        "labels=np.concatenate((label0,label1,label2,label3,label4))\n",
        "labels.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4323, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0195Vsjv-hi"
      },
      "source": [
        "df=pd.DataFrame(data)\n",
        "df['labels']=labels.astype('float32')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RZUTtrPwxhr"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data, train_labels, test_labels=train_test_split(df.iloc[0:,:-1], df['labels'], test_size=0.3, random_state=42, stratify = labels)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dDHRdjazmCk"
      },
      "source": [
        "train_data = np.array(train_data).reshape(len(train_data),150,150,3)\n",
        "test_data = np.array(test_data).reshape(len(test_data),150,150,3)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6up4gCD0ZKm"
      },
      "source": [
        "train_labels = np.array(train_labels).astype('float32')\n",
        "test_labels = np.array(test_labels).astype('float32')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H86NG8oB0bot"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "train_labels=to_categorical(train_labels)\n",
        "test_labels=to_categorical(test_labels)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtVzDnYr01oi"
      },
      "source": [
        "import keras\n",
        "img_preprocessing = keras.preprocessing.image.ImageDataGenerator(\n",
        "    zca_epsilon=1e-06,\n",
        "    rotation_range=0,\n",
        "    width_shift_range=0.0,\n",
        "    height_shift_range=0.0,\n",
        "    brightness_range=None,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.2,\n",
        "    channel_shift_range=0.3,\n",
        "    fill_mode=\"nearest\",\n",
        "    cval=0.0,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    rescale=None,\n",
        "    preprocessing_function=None,\n",
        "    data_format=None,\n",
        "    validation_split=0.0,\n",
        "    dtype=None,\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmjXotpP03dx"
      },
      "source": [
        "img_preprocessing.fit(train_data)\n",
        "img_preprocessing.fit(test_data)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4xHT5-e1Wg5"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import  layers"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz9HcB6V4Vm2",
        "outputId": "1b650ac2-35bc-4ea7-b38b-4a7d28706d9d"
      },
      "source": [
        "train_data.shape[1]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDUO368C1qnB"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(layers.Dense(512, activation='relu' , input_shape=(150,150,3,)))\n",
        "model.add(layers.Dense(5, activation='softmax'))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKFTyzjY10ng"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toLBmGXh2g7Z"
      },
      "source": [
        "result = model.fit(\n",
        "          x= train_data,\n",
        "          y= train_labels,\n",
        "          batch_size = 30,\n",
        "          epochs=100\n",
        "         \n",
        "        \n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5GZ_Kgy2tNB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}